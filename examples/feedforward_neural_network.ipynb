{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from mlscratch.loss_functions import binary_cross_entropy\n",
    "from mlscratch.activation import *\n",
    "from mlscratch.nn_layers import fully_connected\n",
    "\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.architecture = []\n",
    "        self.weights = [] # TODO: change to np.array() blank array if possible. # sudo code\n",
    "        self.local_node_gradients = []\n",
    "        self.loss_partial_gradients = []\n",
    "        self.loss_function = None\n",
    "        self.optimizer = None\n",
    "        \n",
    "    def add(self, layer):\n",
    "        self.architecture.append(layer)\n",
    "\n",
    "    def compile(self, input_size):\n",
    "        self.architecture.insert(0, fully_connected(num_nodes=input_size, activation=no_activation))\n",
    "        for i in range(0, len(self.architecture)-1):\n",
    "            self.weights.append(self._weight_initialization(self.architecture[i], self.architecture[i+1]))\n",
    "            \n",
    "    def train(self, \n",
    "              x,\n",
    "              y, \n",
    "              epochs, \n",
    "              learning_rate=0.001,\n",
    "              beta=0.9,\n",
    "              beta2=0.9,\n",
    "              velocity=0,\n",
    "              sqr_velocity=0,\n",
    "              epsilon=0.000001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "        self.beta2 = beta2\n",
    "        self.velocity = velocity\n",
    "        self.epsilon = epsilon\n",
    "        self.sqr_velocity = sqr_velocity\n",
    "\n",
    "        for _ in epochs:\n",
    "            self._forward_pass(input_values=x, y)\n",
    "            self._backward_pass()\n",
    "\n",
    "\n",
    "    def validate(self, x, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self._forward_pass(input_values=x)\n",
    "\n",
    "    def _forward_pass(self, x, y):\n",
    "        for index, layer_weights in enumerate(self.weights):\n",
    "            output_values = self.architecture[index+1].activation.evaluate((np.dot(input_values, \n",
    "                                                                                   layer_weights.transpose())))\n",
    "            local_layer_gradients = self.architecture[index+1].activation.derivative(output_values, input_values)  \n",
    "            self.local_node_gradients.append(local_layer_gradients)\n",
    "            input_values = output_values\n",
    "            \n",
    "        output = input_values        \n",
    "        return output\n",
    "    \n",
    "    def _backward_pass(self):\n",
    "        for index in range(0, len(self.weights)):\n",
    "            if index == len(self.weights):\n",
    "                self.loss_partial_gradients.append(self.weights[index])\n",
    "            elif index == len(self.weights) - 1:\n",
    "                node_weights = self.weights[index+1]\n",
    "                loss_partial_layer_gradients =self.weights[index] * node_weights\n",
    "                self.loss_partial_gradients.append(loss_partial_layer_gradients)\n",
    "            else:\n",
    "                node_weights = self.weights[index+1]\n",
    "                for index2 in range(index+2, len(self.weights)):\n",
    "                    node_weights = np.dot(node_weights, self.weights[index2])\n",
    "                loss_partial_layer_gradients = self.weights[index] * node_weights\n",
    "                self.loss_partial_gradients.append(loss_partial_layer_gradients)\n",
    "                \n",
    "        self.weights, self.velocity, self.sqr_velocity = \\\n",
    "            self.optimizer(theta_array=self.weights,\n",
    "                           learning_rate=self.learning_rate,\n",
    "                           beta1=self.beta,\n",
    "                           beta2=self.beta2,\n",
    "                           velocity=self.velocity,\n",
    "                           sqr_velocity=self.sqr_velocity,\n",
    "                           gradient=self.loss_partial_gradients,\n",
    "                           epsilon=self.epsilon)\n",
    "            \n",
    "    def _weight_initialization(self, layer_l_minus1, layer_l):\n",
    "        num_nodes_layer_l_minus1 = layer_l_minus1.num_nodes\n",
    "        num_nodes_layer_l = layer_l.num_nodes\n",
    "        weight_matrix = np.random.randn(num_nodes_layer_l, num_nodes_layer_l_minus1) * \\\n",
    "                  np.sqrt(2/num_nodes_layer_l_minus1)\n",
    "        return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo code\n",
    "from mlscratch.nn_layers import fully_connected\n",
    "from mlscratch.optimization import adam\n",
    "from mlscratch.activation import relu, sigmoid\n",
    "from mlscratch.loss_functions import binary_cross_entropy\n",
    "\n",
    "neural_network = NeuralNetwork()\n",
    "neural_network.add(layer=fully_connected(num_nodes=10, activation=relu))\n",
    "neural_network.add(layer=fully_connected(num_nodes=10, activation=relu))\n",
    "neural_network.add(layer=fully_connected(num_nodes=1, activation=sigmoid))\n",
    "neural_network.loss_function = binary_cross_entropy\n",
    "neural_network.optimizer = adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(np.arange(100))\n",
    "delta = np.random.uniform(0,10, size=(100,))\n",
    "y = (.4 * x +1 + delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "# sudo code\n",
    "input_size = 100\n",
    "neural_network.compile(input_size)\n",
    "neural_network.train(x, y, batch_size=20)\n",
    "print(x.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.22512525e-05])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlscratch.activation.relu at 0x7f7b9314ae10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.architecture[2].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          2.44518733  0.          0.          2.44518733  2.44518733\n",
      "   2.44518733  0.          2.44518733  0.        ]\n",
      " [ 0.         51.26715052  0.          0.         51.26715052 51.26715052\n",
      "  51.26715052  0.         51.26715052  0.        ]\n",
      " [ 0.         57.35329001  0.          0.         57.35329001 57.35329001\n",
      "  57.35329001  0.         57.35329001  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.         18.91312444  0.          0.         18.91312444 18.91312444\n",
      "  18.91312444  0.         18.91312444  0.        ]\n",
      " [ 0.         19.34789894  0.          0.         19.34789894 19.34789894\n",
      "  19.34789894  0.         19.34789894  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "[0.         0.00299583 0.         0.         0.00369071 0.00354256\n",
      " 0.00410826 0.         0.00114035 0.        ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bb3c0d8ecba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_node_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_node_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(neural_network.local_node_gradients)):\n",
    "    print(neural_network.local_node_gradients[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
